---
title: "从何从0到1用AI构建一个AI产品"
date: 2025-12-23
draft: false
tags: ["从0到1", "AI","AI产品","agent","RAG"]
---


在AI技术爆发的今天，各方面的的门槛正在被无限拉低。作为一名产品经理，我一直在思考：在AI时代，我们在职业上的核心壁垒是什么？

我的答案是：对业务场景的洞察和对架构的理解。

本文将复盘我如何从零开始，利用 Cursor、Gemini 等 AI 工具，构建一款具备差异化竞争力的 AI 健康应用。这不仅是一个 Demo 的实现，更是一次关于 多模态感知 + 混合专家 Agent (MoE) 架构的落地实践。


# 一、产品立项

每个人脑子里都闪过很多点子，有的天马行空，有的似乎触手可及。我习惯从自己和身边人的真实生活里寻找灵感——那些反复出现、未被很好解决的“小麻烦”，往往藏着机会。

## 我想做什么
这一次，我想做一款健康类应用，聚焦于绝大多数人日常最相关的两件事：吃和动——饮食和运动

## 我为什么想做
- 身边的人或多或少都出现一些健康问题；比如有人天天喊着减肥，却迟迟没有行动起来的我
- 我希望这个产品能够帮助更多人
- 这是一次AI的实践，AI并不是玩具，而是生产力

从0到1的阶段，最好从一个工具做起，别一开始就幻想搭建平台。平台需要平衡供需，强依赖运营；而一个好工具，只要切准一个痛点，就能自然生长。

## 我打算怎么做

打开应用商店，健康类 App 琳琅满目，功能却千篇一律：查热量、记账式录入、生成食谱等

痛点在哪里？

减肥不仅是技术问题，更是心理战。现有的产品要求用户承担极高的执行成本（称重、搜索、录入），却只能获得延迟满足（一个月后体重秤的变化）。这种“高投入、低反馈”的机制，是大多数人半途而废的根源。



<img width="278" height="688" alt="image" src="https://github.com/user-attachments/assets/0d2823e4-ddad-415f-8ab6-11d67c23f2a7" />   <img width="278" height="688" alt="image" src="https://github.com/user-attachments/assets/c8ab4473-dbfc-4c0c-a2b4-4bd94178e64e" />
<img width="278" height="688" alt="image" src="https://github.com/user-attachments/assets/15391904-dd4a-4468-89b8-36ce3e9cfe36" />


所以我的想法是：
- 功能AI化
- 体验游戏化
- 数据可视化

  AI 负责“降本”：拍照即识别，自然语言即记录，把用户操作降到最低。

  游戏负责“增效”：引入即时反馈机制，引入成就、积分、进度可视化等游戏元素，让健康行为像闯关一样获得即时正反馈。。

  数据即体验：将各项数据可视化，给用户最直观的体验，将抽象的热量、营养数据，转化为直观的图表和趋势，让进步“看得见”

  致力于让健康管理变得轻松、有趣、可持续。
  

# 二、工具：今天，每个人都可以是“建造者”

很多人对“做一个产品”感到畏惧，觉得一定要会写代码、有团队、拉投资。但今天，开发的门槛已被 AI 极大地降低。我的整个构建过程，几乎没有手写一行代码。

1. 工具准备：打破第一步障碍

科学上网：这是接触前沿AI工具的桥梁。

获取账号：ChatGPT、Cursor、GitHub Copilot、Gemini… 许多工具在国内直接使用有门槛，但解决方法很简单——去电商平台花几十元，就能获得可用的现成账号。别让注册步骤卡住想法。

安装与上手：跟着教程一步步来，半小时内就能让AI编程助手跑起来。

2. 工具使用：“氛围编程”时代
现在的AI IDE（如Cursor、Antigravity）已经实现了“vibe coding”——不需要记忆语法，只需用自然语言描述想要什么功能。比如：“请创建一个React页面，
包含一个食物拍照上传按钮，下方显示历史记录列表。” AI会生成代码，你只需调整和确认。


# 三、产品实现

实现分两步走：

前端快速搭建：利用 Google AI Studio 等工具，用自然语言描述页面布局和交互，AI能快速生成可用的前端代码。这一步重在验证交互流畅度和视觉观感。

后端与AI核心开发：使用 Cursor 等AI编程IDE，实现业务逻辑和数据存储。

这是我利用Google AI Studio生成的前端页面

<img width="320" height="1024" alt="image" src="https://github.com/user-attachments/assets/ca22dffd-9509-42a3-aff9-73a33f5f3de5" /> <img width="360" height="1236" alt="image" src="https://github.com/user-attachments/assets/bbce9f12-bea1-4520-bb7f-ccb0f2e8290e" />
<img width="398" height="1344" alt="image" src="https://github.com/user-attachments/assets/d86d9032-75ce-44dc-b274-089dd75ca81d" />

真正的挑战与重点在于：如何让AI深度融入产品逻辑？

我梳理了几个核心场景：

用户拍了一张午餐照片，AI需识别其中食物，并估算热量及营养成分。

识别后，AI需询问用户确认，并将数据存储，用于生成每日报告。

用户问：“我明天该怎么吃？”AI需结合用户的体检数据、健康目标（如月减2公斤）、饮食偏好（如不吃辣）甚至当地天气（如下雨不宜户外跑），生成个性化的饮食和运动建议。

用户可能追问：“这个减脂餐具体怎么做？”AI需要给出详细菜谱。

这些场景交织在一起，需要一个灵活的AI系统来支撑，而不是一个简单的问答机器人。

架构演进：从“单轮路由”到“智能体协作”
最初的设计是“单轮分类路由”——用户输入后，系统判断意图并分配给一个处理模块。但很快发现问题：用户的请求常常是复合型的（如“这盘菜热量高吗？我今晚该怎么运动弥补？”），单轮处理显得笨拙。

于是，架构升级为 “规划-编排-执行”体系，其核心理念是：

<img width="874" height="590" alt="image" src="https://github.com/user-attachments/assets/ab37a71d-46af-4585-a7e7-baaec6f9b5c4" />


1. 眼睛：多模态感知层
模型：Qwen-VL-Plus (或其他视觉大模型)

逻辑：用户上传图片（如一碗面），AI 自动提取关键信息（食物名称：红烧牛肉面、估算重量：300g、营养成分），将其转化为结构化文本，追加到用户的 Prompt 中。

2. 大脑：意图拆解与编排 (Planner & Orchestrator)
这里采用了 CoT (Chain of Thought) 的思想。意图识别不再是分类，而是拆解。
利用 Qwen-Plus 将用户的复杂需求拆解为 SubTask 序列，例如：

Task 1 (知识类): 查询红烧肉热量。

Task 2 (规划类): 基于 Task 1 的摄入量，计算今日剩余热量额度。

Task 3 (建议类): 结合雨天环境，推荐室内运动方案。

上下文穿透 (Context Injection) 是关键：Task 1 的执行结果（红烧肉500大卡）会自动注入到 Task 2 的上下文中，确保逻辑连贯。

3. 手脚：混合专家 Agents (MoE)
为了保证专业性和安全性，我将“动脑”与“动手”严格分离：

🧐 规划型 Agent (The Planner) —— 严谨的营养师

人设：逻辑缜密，不苟言笑。

权限：读取用户档案（性别、体重、过敏源）、读取 Todo 列表。

禁区：严禁联网瞎编。只负责基于现有数据进行逻辑推演。

📚 知识型 Agent (The Researcher) —— 博学的图书馆员

人设：知识渊博，海纳百川。

权限：RAG 检索本地营养库、联网搜索最新菜谱、进行复杂数学计算（卡路里换算）。这里的rag是基于dify的本地知识库搭建而成的

禁区：无写入权限。只读不写，防止污染数据库。

✍️ 行动型 Agent (The Clerk) —— 忠实的记录员

人设：执行力强，一丝不苟。

权限：写入数据库（Log）、更新用户记忆（Memory）、修改待办状态。

触发：只有当用户明确确认（“记下来”、“保存”）或规划层下达指令时才行动。

---

**举例来说：**

用户说：“我中午吃了红烧肉，会影响我减肥吗？晚上该怎么调整？”

多模态感知：如果用户上传了图片，先由视觉模型识别出“红烧肉，约300克”。

意图拆解：规划型Agent将问题拆解为：①查询300克红烧肉的热量信息；②评估该热量对用户当日目标的影响；③生成晚餐调整建议。

任务编排：调度中心依次执行：先派知识型Agent查热量；然后将结果传给规划型Agent，结合用户目标进行分析；最后，规划型Agent生成包含具体菜品的晚餐计划，并由行动型Agent存入待办事项。

综合输出：将最终建议流畅地回复给用户：“中午的红烧肉约含500大卡。您今日目标剩余热量为400大卡，建议晚餐以蔬菜沙拉（食谱如下）为主，并配合20分钟居家燃脂运动。”

**关键技术落地**

食物/运动识别与计算：通过 RAG技术，将权威食物热量数据库、运动消耗量表构建成本地知识库，供AI精准查询，避免大模型“幻觉”，这里的RAG是基于dify的本地知识库搭建而成的

个性化推荐：规划型Agent根据用户档案（身体数据、目标、偏好、历史记录）进行逻辑推理，生成“千人千面”的方案。

交互自然化：所有技术架构最终隐藏在背后，用户面对的是一个善解人意、 proactive（主动）的健康伙伴。

环境感知：在推荐运动时，系统会校验天气数据。“雨天不能跑步”不再是死板的规则，而是 AI 给出“推荐做 20 分钟 HIIT”的温情建议。

---

在我实际体验了这种多agent架构体系后，发现一个比较严重的问题——延迟太高了！而且成本与 Token 消耗激增，不太适合快速问答的业务场景，需要低延迟的架构体系

所以，采用了新的AI架构「轻量 Router + 单 Agent ReAct」

<img width="1176" height="890" alt="image" src="https://github.com/user-attachments/assets/636e596e-ce1c-4f1c-8efd-c2b8e4bfae42" />


**1、架构说明**


 **1.1、路由层 (大脑的守门人)**
 
模型: qwen-turbo (速度优化)

逻辑: 分析用户输入和历史记录，将意图分类为：

SIMPLE (简单): 问候、天气查询、单一事实问答。 -> 快速通道 (Fast Path)

COMPLEX (复杂): 规划、饮食建议、多步推理。 -> 慢速通道 (Slow Path)

目的: 将流量导向合适的模型，以节省成本并降低延迟。

**1.2、编排层 (统一智能体)**

模型: 根据路由决策动态切换 (qwen-turbo 或 qwen-plus)。

框架: LangChain AgentExecutor 配合 create_tool_calling_agent。

功能: 维护对话状态（显存）、理解复杂指令，并编排各种“工人”（工具）的执行。

人设系统: 动态加载系统提示词（如“严厉教练”、“温柔姐姐”、“大白菜吉祥物”），在不改变核心逻辑的情况下调整语气。

**1.3、工人层 (工具集)**

“工人”是执行特定任务的专用工具。编排器agent根据需要调用它们。


| 类别   | 工具名称                  | 描述                                     | 动力来源                        |
|--------|--------------------------|----------------------------------------|--------------------------------|
| 知识   | search_health_knowledge  | 检索增强生成 (RAG) 以查找事实。         | Dify / 向量数据库              |
| 知识   | search_recipes           | 实时食谱网页爬虫。                      | 下厨房解析器 (RecipeService)   |
| 计算   | calculate_exercise_calories | 基于 METs 的精确卡路里消耗计算。        | ExerciseCalculator             |
| 计算   | estimate_diet_calories   | 基于 LLM 的非结构化食物热量估算。        | LLM (One-shot)                 |
| 记忆   | get_user_context_summary  | 聚合用户档案、目标和历史记录。           | Postgres (关系型数据)          |
| 记忆   | remember_fact            | 存储长期用户事实/偏好。                  | Postgres (记忆存储)            |
| 记忆   | forget_fact              | 删除过时或错误的记忆。                    | Postgres                       |
| 行动   | add_activity_log         | 记录饮食/运动到每日日志。                | CRUD                           |
| 行动   | assign_daily_todos       | 创建可执行的待办事项。                    | CRUD                           |
| 行动   | get_today_todos          | 查询今日待办列表。                        | CRUD                           |
| 行动   | update_todo              | 更新待办状态或内容。                      | CRUD                           |
| 环境   | check_weather            | 获取实时天气以提供户外建议。             | 天气 API                        |
| 视觉   | analyze_food_image       | 分析上传的食物照片以获取名称/热量。       | qwen-vl-plus (视觉模型)        |
| 知识库 | save_user_document       | 保存用户的重要结构化文档。               | Postgres (用户文档表)          |


**2. 关键工作流**

**2.1 聊天循环 (Chat Loop)**

输入: 用户输入文本或图片。

视觉 (可选): 如果包含图片，qwen-vl-plus 分析图片，提取“食物名称 + 重量”。

路由: qwen-turbo 判定是简单对话还是复杂任务。

编排: 启动并运行相应的智能体。

执行:

- 智能体思考：“我首先需要用户上下文。” -> 调用 get_user_context_summary。
- 智能体思考：“现在我需要计算热量。” -> 调用 estimate_diet_calories
- 智能体思考：“现在我可以回答了。” -> 生成最终回复。

**2.2 目标分析**

主要聊天循环之外的独立服务。

触发: 用户设定新的健康目标（例如，“1个月瘦10斤”）。

逻辑: 使用 qwen-plus 根据医学标准（如每周最多减重1公斤）对目标进行合理性检查。

输出: 生成结构化计划（饮食 + 运动建议）+ 初始待办事项。

**2.3 后台规划** 

作为每日定时任务/后台作业运行。

输入: 用户档案 + 天气预报 + 长期记忆。

逻辑: “鉴于今天下雨且用户膝盖不好，他们应该做什么？”

输出: 3-5 条具体、可执行的待办事项（例如，“室内瑜伽”，“吃燕麦”）。


这是agent一个核心的工作模式：Re Act——一边思考一边行动（思考-行动-观察）

通过**prompt**+ **function call（tool use）** + **代码逻辑（Driver Loop）** 实现

- 提示词层 (The Protocol) - "告诉模型有什么工具"
  
并没有在 System Prompt 里手写 "Please use format: Thought... Action..." 这种复杂的格式指令（这是早期的做法）。 相反，主要做了工具定义。

实现原理： 当调用 LLM API 时，LangChain 会自动把这些 Python 函数转换成一个 JSON Schema 描述，并通过 API 的 tools参数传给 Qwen 模型。就像这样告诉型：

"你可以调用一个叫 
calculate_exercise_calories
 的函数，它需要参数 duration (int) 和 type (string)。"

 
2. 模型层 (The Brain) - "原生支持"
   
现代模型（如 Qwen-Plus, GPT-4）经过了专门的 Fine-tuning (微调)。 当它们接收到 tools
 参数后，如果不单纯回答问题，而是认为需要使用工具，它们不会输出普通的文本。

它们会输出一个特殊的数据结构（API 响应中的 tool_calls 字段），而不是普通的 content。

普通回复：content: "你好"
ReAct 触发：content: null, tool_calls: [{name: "calculate_exercise_calories", args: "..."}]

这比纯提示词控制要稳定得多，因为它是由模型底层的训练数据保证的。

3. 代码层 (The Loop) - "跑腿的执行者"

在一个 while 循环 里运行：

- 发请求：把用户的话 + 工具定义发给 LLM。
- 检测：LLM 返回了单纯的文本？还是返回了 tool_calls 指令？
- 拦截：如果是 tool_calls，代码拦截下来，不显示给用户。
- 执行：代码在本地找到对应的 Python 函数（如 calculate_exercise_calories），真正运行它。
- 反馈：把函数的运行结果（如 "200千卡"）封装成一个特殊的 ToolMessage，喂回 给 LLM。
  
这一步至关重要，让 LLM 觉得它刚刚“看到了”结果。

循环：LLM 拿到结果后，再次思考，直到它决定不再调用工具，而是输出最终文本。

<img width="808" height="1368" alt="image" src="https://github.com/user-attachments/assets/5cbe3655-c5eb-430d-9112-cda13f76fb93" />




# 最后

一个好的AI产品，不是技术的堆砌。它需要：

深刻的场景洞察：找到那些成本高、频率高的痛点。

清晰的产品哲学：我们通过AI，究竟要为用户创造何种体验？（是极致高效，还是温暖陪伴？）

严谨的架构设计：让AI能力可靠、安全、可控地服务于业务逻辑。

健康管理是一件长期且反人性的事。我们的目标，不是用AI制造另一个冰冷的记录工具，而是创造一个懂你、陪你、帮你降低坚持成本的“数字伙伴”。技术永远在迭代，但对人的理解与关怀，才是产品最核心的竞争力。
