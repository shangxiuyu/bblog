---
title: "Agent"
date: 2025-01-23
draft: false
tags: ["Agent", "AI", "智能体"]
---

## 什么是Agent

Agent最初的定义来源于哲学——能够自主行动的实体，在深度学习领域，Agent是一个能够推理、规划、感知环境和使用工具完成任务的应用程序

在大语言模型兴起之前，Agent的实现思路有很多

- 基于符号逻辑
- 基于强化学习
- 基于迁移学习
- ……

直到最近几年的大语言模型技术的成熟，llm的推理、规划、决策等能力让业界普遍认为是实现Agent的最佳路径

- llm作为Agent的大脑，负责处理信息、推理并规划行动
- 外部工具作为Agent的手脚，负责处理特定的任务，通过mcp协议连接外部工具

一个Agent系统在接受用户的输入请求后，会交替调用以下两个流系统

- 一个 **LLM**（**推理模型**”）用于根据输入、可能自动检索的额外上下文以及累积的对话来决定采取什么行动。推理模型将输出（a）阐述下一步行动应该是什么的推理文本，以及（b）指定行动的结构化信息（哪个行动，行动输入参数的值等）。输出的“行动”也可能表示没有剩余的行动可采取。
- **工具** ，这些工具不一定与 LLM 有关，它们可以执行各种行动（由推理模型指定），生成结果，这些结果将被纳入下一次调用推理模型的信息中。推理模型本质上是被提示在系统可访问的一组工具和行动中进行选择。


<img width="376" alt="image" src="https://github.com/user-attachments/assets/2e0b3098-3a0c-40c7-8f68-e73d00eb5446" />


举个例子：

当前用户有一个请求：帮我输出一份上海一日游的景点

> AI系统：根据用户输入的提示词，自动生成一份关于上海景点的介绍
> 
> Agent系统：根据用户输入的提示词，调用llm推理下一步行动，调用浏览器工具，输入上海景点，根据浏览器的输出结果决定下一步是否需要调用更多其他工具完善景点介绍，最后输出
> 
> AI workflow：根据用户输入的提示词，调用llm提取关键词：上海，在工具里输入上海，输出上海的景点介绍，最后输出

<aside>
🔑llm不是作为一个内容生成的容器存在，而是作为一个工具选择器的组件存在
</aside>

<img width="776" alt="image" src="https://github.com/user-attachments/assets/03cffa7a-0718-41a0-8b17-fb212097c339" />


## 当前Agent的主流框架

**1、规划**

规划的任务是目标拆解、反思和优化

- **目标拆解：**将用户的一个复杂的目标拆解成若干个子目标，更易于管理和实现
- **反思和优化：**对过去的错误的行为进行自我批判反思，提取经验，优化未来的行动，提高最终结果的质量

**2、记忆**

拥有长期记忆和短期记忆

- 短期记忆：上下文记忆，记住用户刚刚说了什么内容
- 长期记忆：通过利用外部向量存储和快速检索来实现的长时间记忆

**3、工具**

能够使用外部工具来实行规划的动作，并将执行结果反馈给llm

## Agent的基本实现原理

**（1）LLMs 接收用户指令** 用户指令可以是直接文本输入，还可以是图片、音频、或者通过 @ 等方式引用的外部资料。这些内容会直接作为提示词输入到 LLM 中。

**（2）LLMs 在内部进行推理和规划，生成要执行的具体步骤** LLM 推理用户指令，生成下一步具体的操作。根据具体指令，这一阶段可以是单纯的文本输出（类似问答）或者工具使用，更智能的 Agent，还会对用户进一步询问。

**（3）使用工具完成要执行的具体步骤** 对于 ChatGPT，LLMs 会通过 Function Calling API 返回下一步操作要使用到的工具，比如网页搜索、阅读文件等等。

此时 LLMs 会等待执行操作的返回结果。

**（4）LLMs 重新规划** 根据上一步的返回结果，LLMs 进行重新任务规划。如果 LLMs 认为任务可以结束，则终止这一循环过程
