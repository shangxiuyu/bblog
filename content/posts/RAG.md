---
title: "RAG"
date: 2025-11-13
draft: false
tags: ["AI", "RAG"]
---

RAG（检索增强生成）是一种 AI 框架或技术，旨在增强大型语言模型 (LLM) 的能力，使其能够引用其训练数据之外的外部知识库（Non-Parametric Memory）来生成回复

1. 检索 (Retrieval)： 系统根据用户查询，从外部知识库（如向量数据库）中找到最相关的文档片段或数据。
2. 增强 (Augmentation)： 将检索到的信息作为上下文，添加到用户原始的 Prompt 中，从而丰富查询信息。
3. 生成 (Generation)： LLM 利用增强后的 Prompt 和其内部知识来生成更准确、更具情境化的最终回复。

所以RAG本质上是一个工程化的框架/解决方案，用来赋能llm，有两个词用来解释RAG和llm的关系很形象：“开卷考试”、“闭卷考试”
<img width="1354" height="722" alt="image" src="https://github.com/user-attachments/assets/414b3b28-ae0b-466c-8905-de3b221559f6" />


# 价值

克服静态知识截止日期： RAG 允许 LLM 访问实时或最新的信息，避免因模型训练数据过时而产生错误。
• 降低幻觉风险： 通过将回复奠基于检索到的事实数据，RAG 大幅减少了 LLM 胡编乱造（幻觉）的可能性，增强了回答的可靠性。
• 提供透明度： RAG 允许系统在回复中提供来源引用（Citation），使用户可以验证信息的准确性

所以RAG在企业落地AI场景中应用非常广泛，譬如AI客服、AI导购、AI搜索、AI问答、企业知识库等


# RAG是什么？怎么深度理解RAG？

<img width="2810" height="1146" alt="image" src="https://github.com/user-attachments/assets/abddceed-a6fd-418e-9e2f-7631d216a18f" />


想象一下，RAG 就像给 AI 配备了专属的私人研究管理员，让它先回答你的问题

- 文档：您向系统提供您的文档（公司手册、文章、书籍），就像将书籍添加到图书馆一样。

- 分块：系统将这些内容分解成易于理解的小块：就像图书管理员将书籍分成章节和部分而不是处理整卷一样。

- 嵌入：每个块都被转换成一种特殊的数字格式（向量），以捕捉其含义：类似于创建理解概念而不仅仅是关键字的详细索引卡。

- 索引：这些向量被组织在一个可搜索的数据库中：就像一个了解不同主题之间关系的神奇卡片目录。

- 检索：当您提出问题时，系统会查阅其索引以找到与您的查询最相关的块。

- 生成：人工智能会根据您的问题和这些有用的参考资料来制作答案，从而产生比仅仅依赖预先训练的知识更好的答案。



## 第一阶段：知识库构建与准备（离线过程）
目标是建立一个可信赖、高质量且高效可检索的企业专属知识库，包含【文档输入与解析】、【内容分块与元数据】、【向量化与索引构建】

### 1、文档

一般来说，企业内部会有很多不同格式、不同类型的非结构化知识库文档，文档里可能会有表格、图片、文本等，所以RAG的第一步就是要对所有的文档进行解析，
文档解析的核心目标是将其转化为结构化的纯文本形式，通常是 Markdown (md) 格式。Markdown 格式具有一级标题、二级标题等规范结构，更容易被大模型理解和阅读，当前有几种常见的文档解析方式

- OCR识别
- 文档解析
- 多模态大模型

ocr识别技术目前相当成熟，但是对于复杂文档的识别效果很差，多模态大模型成本高、效果不稳定，所以现在一般主流选择的是文档解析+ocr混合，国内大厂都有现成的文档解析，也有很多免费开源的项目

- 百度智能云：https://ai.baidu.com/ai-doc/OCR/Klxag8wiy
- 阿里云 文档智能：https://www.aliyun.com/product/ai/docmind
- 智谱文件解析：https://docs.bigmodel.cn/cn/guide/tools/file-parser

免费开源文档解析工具：
- pdfplumber：https://github.com/jsvine/pdfplumber
- PDFMiner：https://github.com/pdfminer/pdfminer.six
- deepdoctection：https://github.com/DeepDoctection/deepdoctection



### 内容分块：将文档分解成可管理的部分

为了让 RAG 系统有效运作，我们需要将文档分解成更小、更易消化的部分。

为什么组块很重要？

块的大小直接影响 RAG 系统的检索质量：

块太大：系统可能检索了太多不相关的信息

块太小：可能会丢失重要的内容

恰到好处的块：系统准确地找到它所需要的（完美的部分！）

切块策略： 优先采用语义分块或结构化分块（按段落、章节、标题）来保持语义连贯性，避免固定长度切割导致的“语义切断”。
   - 重叠机制（Overlap）： 在连续的切块之间设置 10%~30% 的重叠部分，以确保重要信息不会在切块边界被分割，并增加检索命中几率
<img width="2170" height="1074" alt="image" src="https://github.com/user-attachments/assets/aa6aaaa1-7da2-4079-b235-7d65ff8517b7" />

主流的切块工具推荐：

在 RAG 管道中，切块功能通常由开源框架或专业工具提供：

1. RAG 编排框架（内建 Text Splitter）
   
这些框架提供了模块化的文本分割器和数据处理管道：

- LangChain： 提供各种 Text Splitters 模块，用于处理不同类型文档的分块逻辑。
- LlamaIndex： 专注于高效索引和数据处理，其 IngestionPipeline 对象支持配置精细的预处理和切块步骤。
- Haystack： 一个开源的 NLP 平台，也提供 RAG 管道组件。
  
2. 专业处理库/工具

• NLP 库： NLTK 或 spaCy 可以用于基础的句法分析，辅助基于句子的切块。
• 开源知识库平台： 一些开源平台（如 RAG Flow 或类比 Coze/Dify）在文档上传时会集成自动解析和切块能力


### 向量化与索引构建

**向量化：** 使用嵌入模型（如 BGE 或 E5）将文本切块转换为高维数值向量（Embedding），用于衡量语义相似度

**索引：** 将向量存储到向量数据库中，并建立索引以支持高效检索（如 Pinecone, Qdrant, Milvus），目的是为“知识库”构建高效的“目录”，索引决定了了信息检索的速度与精度

索引的几个策略：
- 关键词索引
- 向量索引
- 混合索引

<img width="2170" height="964" alt="image" src="https://github.com/user-attachments/assets/49783a68-b9be-4c56-a21d-267cd90bb089" />


## 第二阶段：在线检索与生成（Retrieval & Generation）

该阶段是系统对用户实时提问的响应流程。包含【查询理解与路由】、【检索与重排序】、【大模型生成】、【后置处理与缓存】


### 查询理解与路由

**意图识别**：当用户输入了一段话，系统需要能够识别理解用户的意图，一般使用llm prompt来进行意图识别，来判断用户的意图是什么？比如退款、比如查询某信息

意图识别是比较关键的一步，如果意图识别不精准，后续的检索与生成就差十万八千里，所以一般为了提高llm的意图识别能力，也会有很多工程化的解决方案
- prompt：提示词里增加一些Few-Shot 示例，来帮助大模型更好的理解，根据业务场景，清晰定义系统支持哪些意图（例如，在银行场景中可定义为“账户查询”、“转账汇款”、“挂失/冻结”等
- 多轮对话：大模型通过多次与用户的对话来精准锁定用户的意图，比如用户第一次表述根本不精准
- 微调：根据与用户的数据对话来微调大模型，但成本过高

和企业无关的用户问题或者带有一些风险的提问，这些意图都会有一个默认回复策略——暂时无法回复这些问题


**查询路由**： 根据用户意图，判断问题应去哪个知识库（如产品、流程、FAQ）以及用何种检索方式（如向量检索、SQL 查询常规数据库）

**查询重写**：旨在解决用户提问中的各种问题，让检索器能够使用更准确的、语义完整的查询语句
 - 同义重写（Query Expansion）： 将用户提问替换成多种同义或相似的说法（例如，将“怎么退钱”改写为“退款流程”），以更大概率地命中知识库中可能存在的不同表达方式的片段
 - 抽象化重写： 抽离用户提问中的干扰信息（如具体日期、人名等），提取出真正想问的底层抽象意图（例如，将“我的信用卡怎么突然扣了年费？”抽象为“查询年费扣除原因”），从而提高检索效率
 - 拆解复杂任务： 将一个包含多个子目标或多段信息的复杂问题分解成更小的、可独立检索的子问题，让系统可以分步查找答案

如何实现查询重写？——prompt工程： 通过设计包含**思维链（Chain-of-Thought, CoT）和少量示例（Few-Shot）**的 Prompt 模板，来指导 LLM 根据历史对话和当前查询，输出一个语义完整的、用于检索的重写后问题



### 检索与排序

检索”和“排序（增强）”是 RAG 流程中在线查询阶段的核心引擎

检索：将优化后的查询向量化，在向量数据库中寻找语义最相似的文档片段。


检索方式：
    1. 向量检索（语义）：基于语义相似度匹配，擅长理解模糊或口语化的提问。
    2. 关键词检索（精确）：基于词汇重叠度，确保精确命中 IDs、专有名词等稀有词汇。
    3. 混合检索（Hybrid Retrieval）：生产环境的标准做法，结合向量检索和关键词检索，确保兼顾广度（召回率）和精度（准确率）


 召回率（Recall）是衡量检索系统信息覆盖度的关键指标

  假设知识库中共有 10 条 正确的、应该被检索出来用于回答用户问题的片段。
  
  如果系统只检索到了 3 条正确的片段，那么召回率就是 3÷10=0.3（30%）



  **重排序（Reranking）**： 对混合检索返回的 Top-k 片段进行重新打分和排序。通过专门的 Re-rank 模型（如 BGE Reranker）确保最相关的片段优先展示，避免将冗余信息（噪音）送入 LLM 上下文窗口

重排序通常是通过调用专门的 Rerank 模型 或 cross-encoder 来实现的。这些模型会接收用户查询和每一个检索到的片段，计算它们之间真正的相关性得分。

主流工具： 业内常用的模型包括 BGE Reranker (在中文开源领域表现优秀) 或商业化的 Cohere Rerank API。

上下文控制： 仅将重排序后得分最高的少数片段（如 Top-3 或 Top-5）送入 LLM 的上下文窗口，以避免上下文腐烂（Context Rot）和降低生成质量

### 生成与缓存

- LLM 利用检索到的高质量上下文，生成准确、合规且风格一致的最终回复
- 结果缓存（Caching） ：存储高频问题/答案（如客服电话、常见流程），快速返回，降低调用 LLM 的成本和延迟

